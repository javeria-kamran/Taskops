# Quickstart Guide: Phase I Console Todo Application

**Feature**: Phase I Console Todo Application
**Date**: December 27, 2025
**Audience**: Developers implementing or reviewing this feature

## Overview

This guide provides step-by-step instructions for setting up, implementing, testing, and running the Phase I Console Todo Application. Follow this guide to get from specification to working code using spec-driven development with Claude Code.

---

## Prerequisites

### Required Software

**Python 3.13+**:
- Check version: `python --version` or `python3 --version`
- Download from: https://www.python.org/downloads/ (if needed)
- Constitutional requirement (FR-016)

**UV Package Manager**:
- Check if installed: `uv --version`
- Install: `pip install uv` or follow https://docs.astral.sh/uv/
- Constitutional requirement (Phase I technology stack)

**Git**:
- Check version: `git --version`
- Download from: https://git-scm.com/ (if needed)
- For version control and spec-kit workflow

### Optional Tools

**VS Code or PyCharm**: For code editing (any editor works)
**Windows Terminal** (for Windows users): Better console experience

---

## Project Setup

### Step 1: Clone Repository (if not already done)

```bash
git clone <repository-url>
cd "Naz Todo"
```

### Step 2: Checkout Feature Branch

```bash
git checkout 001-phase1-console-app
```

**Verify you're on the correct branch**:
```bash
git branch --show-current
# Should output: 001-phase1-console-app
```

### Step 3: Create Virtual Environment with UV

```bash
# Create virtual environment
uv venv

# Activate virtual environment
# On Windows:
.venv\Scripts\activate

# On macOS/Linux:
source .venv/bin/activate
```

**Verify activation**:
- Your command prompt should show `(.venv)` prefix

### Step 4: Install Dependencies

**Create `pyproject.toml`** (if not exists):
```bash
uv init --name todo-console-app --python 3.13
```

**Add development dependencies**:
```bash
uv add --dev pytest pytest-cov pytest-mock
```

**Verify installation**:
```bash
uv pip list
# Should show pytest, pytest-cov, pytest-mock
```

---

## Project Structure

### Expected Directory Layout

```
Naz Todo/
â”œâ”€â”€ specs/
â”‚   â””â”€â”€ 001-phase1-console-app/
â”‚       â”œâ”€â”€ spec.md              # Feature specification âœ…
â”‚       â”œâ”€â”€ plan.md              # Implementation plan âœ…
â”‚       â”œâ”€â”€ research.md          # Technology decisions âœ…
â”‚       â”œâ”€â”€ data-model.md        # Data model specification âœ…
â”‚       â”œâ”€â”€ quickstart.md        # This file âœ…
â”‚       â”œâ”€â”€ contracts/
â”‚       â”‚   â””â”€â”€ cli-interface.md # CLI contract âœ…
â”‚       â”œâ”€â”€ checklists/
â”‚       â”‚   â””â”€â”€ requirements.md  # Quality checklist âœ…
â”‚       â””â”€â”€ tasks.md             # Task breakdown (generated by /speckit.tasks)
â”œâ”€â”€ src/                         # Source code (generated by /speckit.implement)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ task.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ task_manager.py
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ menu.py
â”‚   â”‚   â””â”€â”€ handlers.py
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ validators.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_task.py
â”‚   â”‚   â”œâ”€â”€ test_task_manager.py
â”‚   â”‚   â””â”€â”€ test_validators.py
â”‚   â””â”€â”€ integration/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ test_cli.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## Development Workflow

### Phase 0: Specification & Planning (COMPLETE âœ…)

**Status**: Already complete, you're reading the output!

**Artifacts Created**:
- âœ… `spec.md` - Feature specification with user stories and acceptance criteria
- âœ… `plan.md` - Implementation plan with technical context
- âœ… `research.md` - Technology decisions and rationale
- âœ… `data-model.md` - Task entity specification
- âœ… `contracts/cli-interface.md` - Console interface contract
- âœ… `checklists/requirements.md` - Quality validation
- âœ… `quickstart.md` - This file

### Phase 1: Task Generation

**Command**: `/speckit.tasks`

**What it does**:
- Reads `plan.md` and `data-model.md`
- Breaks implementation into actionable tasks
- Creates `tasks.md` with dependency-ordered tasks
- Each task maps to specific code files and tests

**When to run**: Now! After completing Phase 0 planning

**Output**: `specs/001-phase1-console-app/tasks.md`

### Phase 2: Implementation

**Command**: `/speckit.implement`

**What it does**:
- Reads `tasks.md`
- Generates code using Claude Code for each task
- Creates source files in `src/` directory
- Creates test files in `tests/` directory
- Ensures >80% test coverage

**When to run**: After `tasks.md` is generated and reviewed

**Output**: Complete implementation in `src/` and `tests/`

### Phase 3: Validation

**Run Tests**:
```bash
# Run all tests
pytest

# Run with coverage report
pytest --cov=src --cov-report=html --cov-report=term

# View coverage report
# On Windows: start htmlcov/index.html
# On macOS: open htmlcov/index.html
# On Linux: xdg-open htmlcov/index.html
```

**Verify Coverage**:
- Check that coverage is >80% (constitutional requirement)
- Aim for 90%+ to exceed minimum

**Verify Against Spec**:
- [ ] All functional requirements (FR-001 to FR-020) implemented
- [ ] All acceptance scenarios passing
- [ ] All edge cases handled
- [ ] All success criteria met (SC-001 to SC-010)

### Phase 4: Final Submission

**Create README.md**:
```markdown
# Phase I: Console Todo Application

## Overview
In-memory Python console application for task management with 5 Basic Level CRUD operations.

## Requirements
- Python 3.13+
- UV package manager

## Installation
1. Clone repository
2. Run: `uv venv && source .venv/bin/activate` (or `.venv\Scripts\activate` on Windows)
3. Run: `uv add --dev pytest pytest-cov`

## Usage
```bash
python src/cli/menu.py
```

## Testing
```bash
pytest --cov=src
```

## Features
- Add tasks with title and description
- View all tasks with completion status
- Update task details
- Delete tasks
- Mark tasks as complete/incomplete
- Clean console interface with numbered menu

## Hackathon Phase
Phase I - Basic Level Features Only
Due: December 7, 2025
```

**Update `.gitignore`**:
```
__pycache__/
*.pyc
.pytest_cache/
htmlcov/
.coverage
.env
*.egg-info/
dist/
build/
.venv/
```

**Commit Changes**:
```bash
git add .
git commit -m "Complete Phase I Console Todo Application

Implements all 5 Basic Level features:
- Add Task (FR-002, FR-003)
- View Tasks (FR-005, FR-012)
- Update Task (FR-006)
- Delete Task (FR-007)
- Mark Complete/Incomplete (FR-008)

Generated with Claude Code (SC-006)
Test coverage: >80% (SC-007)
All acceptance scenarios passing

ðŸ¤– Generated with Claude Code (https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

**Push to Remote** (if applicable):
```bash
git push origin 001-phase1-console-app
```

---

## Running the Application

### Quick Start

```bash
# Ensure virtual environment is activated
source .venv/bin/activate  # or .venv\Scripts\activate on Windows

# Run the application
python src/cli/menu.py
```

### Expected Behavior

**Application starts with main menu**:
```
====================================
           Todo Application
====================================

1. Add Task
2. View Tasks
3. Update Task
4. Delete Task
5. Mark Task as Complete/Incomplete
6. Exit

Enter your choice (1-6):
```

**Try adding a task**:
1. Select option 1
2. Enter title: "Test the todo app"
3. Enter description (optional): "Verify all features work correctly"
4. Confirm task created with ID #1

**View tasks**:
1. Select option 2
2. See your task listed with [ ] (pending) status

**Mark as complete**:
1. Select option 5
2. Enter task ID: 1
3. See confirmation that task is completed

**View tasks again**:
1. Select option 2
2. See task with [âœ“] (completed) status

**Exit**:
1. Select option 6
2. Confirm with "yes"
3. Application exits with "Goodbye!" message

---

## Testing Guide

### Running Tests

**Run all tests**:
```bash
pytest
```

**Run with verbose output**:
```bash
pytest -v
```

**Run specific test file**:
```bash
pytest tests/unit/test_task.py
```

**Run with coverage**:
```bash
pytest --cov=src --cov-report=term-missing
```

**Generate HTML coverage report**:
```bash
pytest --cov=src --cov-report=html
```

### Understanding Test Output

**Successful test run**:
```
============================= test session starts =============================
collected 25 items

tests/unit/test_task.py ........                                        [ 32%]
tests/unit/test_task_manager.py .............                           [ 84%]
tests/unit/test_validators.py ....                                      [100%]

============================== 25 passed in 0.45s ==============================

---------- coverage: platform win32, python 3.13.0 -----------
Name                            Stmts   Miss  Cover   Missing
-------------------------------------------------------------
src/models/task.py                 25      0   100%
src/services/task_manager.py       45      2    96%   78-79
src/lib/validators.py              15      0   100%
src/cli/menu.py                    35      8    77%   45-52
src/cli/handlers.py                50     10    80%   89-98
-------------------------------------------------------------
TOTAL                             170     20    88%
```

**Coverage target**: >80% (constitutional requirement)
**This example**: 88% âœ… PASS

### Test Organization

**Unit Tests** (`tests/unit/`):
- Test individual components in isolation
- Fast execution (<1 second total)
- No I/O dependencies

**Integration Tests** (`tests/integration/`):
- Test complete user workflows
- Simulate user input and capture output
- Verify end-to-end functionality

---

## Troubleshooting

### Issue: Python version too old

**Problem**: `python --version` shows <3.13
**Solution**:
1. Install Python 3.13+ from https://www.python.org/downloads/
2. Use `python3.13` command explicitly
3. Recreate virtual environment: `uv venv --python python3.13`

### Issue: UV not found

**Problem**: `uv: command not found`
**Solution**:
```bash
pip install uv
# OR
curl -LsSf https://astral.sh/uv/install.sh | sh  # Linux/macOS
# OR
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"  # Windows
```

### Issue: Import errors when running application

**Problem**: `ModuleNotFoundError: No module named 'src'`
**Solution**:
```bash
# Run from project root directory
cd "Naz Todo"

# Ensure PYTHONPATH includes src directory
export PYTHONPATH="${PYTHONPATH}:${PWD}/src"  # Linux/macOS
set PYTHONPATH=%PYTHONPATH%;%CD%\src  # Windows

# OR install package in editable mode
uv pip install -e .
```

### Issue: Tests failing

**Problem**: Tests fail with assertion errors
**Solution**:
1. Read the error message carefully
2. Check if implementation matches spec requirements
3. Verify acceptance scenarios in `spec.md`
4. Review contracts in `contracts/cli-interface.md`
5. Regenerate code if spec-implementation mismatch found

### Issue: Coverage below 80%

**Problem**: `pytest --cov` shows <80% coverage
**Solution**:
1. Identify uncovered lines: `pytest --cov=src --cov-report=term-missing`
2. Add tests for missing branches (especially error cases)
3. Focus on high-value coverage (business logic in services/)
4. CLI I/O is harder to test, but integration tests help

### Issue: Application crashes on Ctrl+C

**Problem**: Stack trace shown instead of graceful exit
**Solution**:
- Ensure `KeyboardInterrupt` exception is caught in main loop
- Display user-friendly message before exit
- Reference: `contracts/cli-interface.md` â†’ Special Behaviors â†’ Ctrl+C

---

## Performance Validation

### Performance Targets (from spec.md)

| Metric | Target | How to Verify |
|--------|--------|---------------|
| Startup time | <2 seconds | Time from launch to main menu display |
| View 100 tasks | <1 second | Create 100 tasks, time the View operation |
| Add task | <30 seconds | Includes user input time (typing) |
| Menu navigation | <5 seconds | Time between selecting option and next menu |

### Performance Testing

**Manual timing**:
```bash
# Startup time
time python src/cli/menu.py
# (Exit immediately with option 6)
# Verify: <2 seconds

# View 100 tasks (stress test)
# 1. Modify code to auto-create 100 tasks on startup
# 2. Select option 2 (View Tasks)
# 3. Verify: displays in <1 second
```

**Expected Results**:
- All targets easily met (in-memory operations are instant)
- Python 3.13 startup overhead: ~50-200ms
- View 100 tasks: ~10-50ms (rendering time dominates)

---

## Code Quality Checklist

Before submitting, verify:

**Spec Compliance**:
- [ ] All 20 functional requirements implemented (FR-001 to FR-020)
- [ ] All 5 user stories with acceptance scenarios passing
- [ ] All edge cases from spec.md handled

**Testing**:
- [ ] Test coverage >80% (check with `pytest --cov`)
- [ ] All unit tests passing
- [ ] All integration tests passing
- [ ] No skipped or xfailed tests

**Code Quality**:
- [ ] PEP 8 compliant (run `flake8 src/` if available)
- [ ] Type hints present (Python 3.13+ syntax)
- [ ] Self-documenting code (clear naming)
- [ ] Comments only where logic is non-obvious

**Documentation**:
- [ ] README.md exists with setup instructions
- [ ] .gitignore excludes Python artifacts
- [ ] Commit messages reference spec requirements

**Performance**:
- [ ] Application starts in <2 seconds
- [ ] View operation instant (<1 second for 100 tasks)
- [ ] No crashes during normal operation (SC-010)

**Constitutional Compliance**:
- [ ] All code generated by Claude Code (SC-006)
- [ ] Spec-driven process documented (audit trail in git)
- [ ] Clean architecture maintained (models â†’ services â†’ cli)
- [ ] Phase I scope only (no Phase II features)

---

## Next Steps After Phase I

### Phase I Completion

**Deliverables**:
1. Working console application (all 5 Basic Level features)
2. Test suite with >80% coverage
3. Documentation (README.md, specs/)
4. Demo video (<90 seconds)

**Submission**:
- Google Form: https://forms.gle/KMKEKaFUD6ZX4UtY8
- Include: GitHub repo URL, demo video URL, WhatsApp number

**Due Date**: December 7, 2025

### Phase II Preview

**Next Iteration** (not in current scope):
- Transform console app to web application (Next.js frontend + FastAPI backend)
- Add persistent storage (Neon PostgreSQL)
- Implement user authentication (Better Auth with JWT)
- Multi-user support
- RESTful API endpoints

**Migration Path**:
- Task model easily migrates to database (add `user_id`, `updated_at`)
- TaskManager interface remains same (swap in-memory for DB)
- CLI layer can be replaced with web UI

---

## Resources

**Project Documentation**:
- Specification: `specs/001-phase1-console-app/spec.md`
- Implementation Plan: `specs/001-phase1-console-app/plan.md`
- Technical Research: `specs/001-phase1-console-app/research.md`
- Data Model: `specs/001-phase1-console-app/data-model.md`
- CLI Contract: `specs/001-phase1-console-app/contracts/cli-interface.md`

**External Resources**:
- Python Documentation: https://docs.python.org/3.13/
- UV Package Manager: https://docs.astral.sh/uv/
- pytest Documentation: https://docs.pytest.org/
- Claude Code Guide: https://claude.com/claude-code

**Hackathon Resources**:
- Constitution: `.specify/memory/constitution.md`
- Submission Form: https://forms.gle/KMKEKaFUD6ZX4UtY8
- Live Presentations (Sundays 8 PM): Zoom link in constitution

---

## Summary

This quickstart guide provides everything needed to implement the Phase I Console Todo Application using spec-driven development. Follow the workflow: verify setup â†’ generate tasks â†’ implement â†’ test â†’ submit.

**Key Takeaways**:
- âœ… All specifications complete and ready for implementation
- âœ… Technology stack defined (Python 3.13+, UV, pytest)
- âœ… Project structure planned (models, services, cli, lib)
- âœ… Testing strategy clear (>80% coverage requirement)
- âœ… Ready for `/speckit.tasks` to generate task breakdown
- âœ… Clear path from spec to working code via Claude Code

**Next Command**: Run `/speckit.tasks` to generate `tasks.md` and begin implementation!
